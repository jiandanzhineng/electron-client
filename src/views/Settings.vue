<template>
  <div class="settings">
    <div class="settings-header">
      <h1>è®¾ç½®</h1>
      <p>é…ç½®åº”ç”¨ç¨‹åºçš„å„é¡¹è®¾ç½®</p>
    </div>

    <div class="settings-content">
      <!-- TTSè®¾ç½®åŒºåŸŸ -->
      <div class="settings-section">
        <h2>ğŸ”Š TTS (æ–‡æœ¬è½¬è¯­éŸ³) è®¾ç½®</h2>
        
        <!-- TTSæ”¯æŒçŠ¶æ€ -->
        <div class="setting-item">
          <label>TTSæ”¯æŒçŠ¶æ€:</label>
          <span :class="['status', ttsSupported ? 'supported' : 'not-supported']">
            {{ ttsSupported ? 'âœ… æ”¯æŒ' : 'âŒ ä¸æ”¯æŒ' }}
          </span>
        </div>

        <div v-if="ttsSupported">
          <!-- è¯­éŸ³é€‰æ‹© -->
          <div class="setting-item">
            <label for="voice-select">è¯­éŸ³:</label>
            <select 
              id="voice-select" 
              v-model="selectedVoice" 
              @change="onVoiceChange"
              :disabled="loading"
            >
              <option value="">é€‰æ‹©è¯­éŸ³...</option>
              <option 
                v-for="voice in availableVoices" 
                :key="voice.Name" 
                :value="voice.Name"
              >
                {{ voice.Name }} {{ voice.Culture ? `(${voice.Culture})` : '' }}
              </option>
            </select>
          </div>

          <!-- è¯­éŸ³å‚æ•°è®¾ç½® -->
          <div class="setting-item">
            <label for="voice-rate">è¯­éŸ³é€Ÿåº¦:</label>
            <div class="slider-container">
              <input 
                id="voice-rate" 
                type="range" 
                min="-10" 
                max="10" 
                step="1" 
                v-model="voiceRate"
                @input="onVoiceRateChange"
              >
              <span class="slider-value">{{ voiceRate }}</span>
            </div>
          </div>

          <!-- æµ‹è¯•æ–‡æœ¬è¾“å…¥ -->
          <div class="setting-item">
            <label for="test-text">æµ‹è¯•æ–‡æœ¬:</label>
            <textarea 
              id="test-text" 
              v-model="testText" 
              placeholder="è¾“å…¥è¦æµ‹è¯•çš„æ–‡æœ¬..."
              rows="3"
              :disabled="loading || isSpeaking"
            ></textarea>
          </div>

          <!-- æµ‹è¯•æŒ‰é’® -->
          <div class="setting-item">
            <div class="button-group">
              <button 
                @click="testTTS" 
                :disabled="loading || isSpeaking || !testText.trim()"
                class="btn btn-primary"
              >
                <span v-if="isSpeaking">ğŸ”Š æ’­æ”¾ä¸­...</span>
                <span v-else>ğŸµ æµ‹è¯•æ’­æ”¾</span>
              </button>
              <button 
                @click="stopTTS" 
                :disabled="loading || !isSpeaking"
                class="btn btn-secondary"
              >
                â¹ï¸ åœæ­¢
              </button>
            </div>
          </div>
        </div>

        <div v-else class="not-supported-message">
          <p>âš ï¸ å½“å‰ç³»ç»Ÿä¸æ”¯æŒTTSåŠŸèƒ½ï¼Œæˆ–è€…ç¼ºå°‘å¿…è¦çš„ç»„ä»¶ã€‚</p>
          <p>è¯·ç¡®ä¿æ‚¨çš„ç³»ç»Ÿå·²å®‰è£…ç›¸åº”çš„TTSå¼•æ“ã€‚</p>
        </div>
      </div>

      <!-- AIåŠŸèƒ½è®¾ç½®åŒºåŸŸ -->
      <div class="settings-section">
        <h2>ğŸ¤– AIåŠŸèƒ½è®¾ç½®</h2>
        
        <!-- ç»Ÿä¸€API Tokené…ç½® -->
        <div class="ai-subsection">
          <h3>ğŸ”‘ API Token é…ç½®</h3>
          <div class="setting-item">
            <label for="ai-token">ç¡…åŸºæµåŠ¨ API Token:</label>
            <div class="token-input-group">
              <input 
                id="ai-token" 
                type="text" 
                v-model="aiToken" 
                placeholder="è¯·è¾“å…¥ç¡…åŸºæµåŠ¨API Tokenï¼ˆç”¨äºSTTå’ŒLLMåŠŸèƒ½ï¼‰..."
                :disabled="loading"
              >
              <button 
                @click="saveAiToken" 
                :disabled="loading || !aiToken.trim()"
                class="btn btn-primary btn-sm"
              >
                ğŸ’¾ ä¿å­˜
              </button>
              <button 
                @click="testAiConnection" 
                :disabled="loading || !aiConfigured"
                class="btn btn-info btn-sm"
              >
                ğŸ”— æµ‹è¯•è¿æ¥
              </button>
            </div>
            
            <!-- çŠ¶æ€æç¤º -->
            <div v-if="aiStatusMessage" class="status-message" :class="aiStatusType">
              {{ aiStatusMessage }}
            </div>
          </div>

          <!-- é…ç½®çŠ¶æ€ -->
          <div class="setting-item">
            <label>é…ç½®çŠ¶æ€:</label>
            <span :class="['status', aiConfigured ? 'configured' : 'not-configured']">
              {{ aiConfigured ? 'âœ… å·²é…ç½®' : 'âŒ æœªé…ç½®' }}
            </span>
          </div>
        </div>
        
        <!-- STTè®¾ç½®å­åŒºåŸŸ -->
        <div class="ai-subsection" v-if="aiConfigured">
          <h3>ğŸ¤ STT (è¯­éŸ³è½¬æ–‡æœ¬)</h3>

        <div>
          <!-- å½•éŸ³æµ‹è¯•åŒºåŸŸ -->
           <div class="setting-item">
             <label>å½•éŸ³æµ‹è¯•:</label>
             <div class="recording-controls">
               <button 
                 @click="startRecording" 
                 :disabled="loading || isRecording || isTranscribing"
                 class="btn btn-primary"
               >
                 <span v-if="isRecording">ğŸ”´ å½•éŸ³ä¸­...</span>
                 <span v-else>ğŸ¤ å¼€å§‹å½•éŸ³</span>
               </button>
               <button 
                 @click="stopRecording" 
                 :disabled="loading || !isRecording || isTranscribing"
                 class="btn btn-secondary"
               >
                 â¹ï¸ ç»“æŸå½•éŸ³
               </button>
               <button 
                 @click="playRecording" 
                 :disabled="loading || isRecording || isTranscribing || !hasRecording || isPlaying"
                 class="btn btn-info"
               >
                 <span v-if="isPlaying">ğŸ”Š æ’­æ”¾ä¸­...</span>
                 <span v-else>â–¶ï¸ æ’­æ”¾å½•éŸ³</span>
               </button>
               <button 
                 @click="stopPlayback" 
                 :disabled="loading || !isPlaying"
                 class="btn btn-warning"
               >
                 â¸ï¸ åœæ­¢æ’­æ”¾
               </button>
             </div>
           </div>

          <!-- è½¬å½•ç»“æœ -->
          <div class="setting-item" v-if="transcriptionResult">
            <label>è½¬å½•ç»“æœ:</label>
            <div class="transcription-result">
              {{ transcriptionResult }}
            </div>
          </div>

          <!-- è½¬å½•çŠ¶æ€ -->
          <div class="setting-item" v-if="isTranscribing">
            <div class="transcribing-status">
              ğŸ”„ æ­£åœ¨è½¬å½•ä¸­ï¼Œè¯·ç¨å€™...
            </div>
          </div>
        </div>

        </div>
        <!-- STTè®¾ç½®å­åŒºåŸŸç»“æŸ -->
        
        <!-- LLMè®¾ç½®å­åŒºåŸŸ -->
        <div class="ai-subsection" v-if="aiConfigured">
          <h3>ğŸ§  LLM (å¤§è¯­è¨€æ¨¡å‹)</h3>
          
          <div>
            <!-- æ¨¡å‹é€‰æ‹© -->
            <div class="setting-item">
              <label for="llm-model-select">æ¨¡å‹é€‰æ‹©:</label>
              <select 
                id="llm-model-select" 
                v-model="selectedLlmModel" 
                :disabled="loading"
              >
                <option 
                  v-for="model in availableLlmModels" 
                  :key="model" 
                  :value="model"
                >
                  {{ model }}
                </option>
              </select>
            </div>

            <!-- å¯¹è¯æµ‹è¯•åŒºåŸŸ -->
            <div class="setting-item">
              <label for="llm-test-message">å¯¹è¯æµ‹è¯•:</label>
              <textarea 
                id="llm-test-message" 
                v-model="llmTestMessage" 
                placeholder="è¾“å…¥è¦æµ‹è¯•çš„æ¶ˆæ¯..."
                rows="3"
                :disabled="loading || isLlmChatting"
              ></textarea>
            </div>

            <!-- æµ‹è¯•æŒ‰é’® -->
            <div class="setting-item">
              <div class="button-group">
                <button 
                  @click="testLlmChat" 
                  :disabled="loading || isLlmChatting || !llmTestMessage.trim()"
                  class="btn btn-primary"
                >
                  <span v-if="isLlmChatting">ğŸ¤– å¯¹è¯ä¸­...</span>
                  <span v-else>ğŸ’¬ å‘é€æ¶ˆæ¯</span>
                </button>
                <button 
                  @click="clearLlmChat" 
                  :disabled="loading"
                  class="btn btn-secondary"
                >
                  ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯
                </button>
              </div>
            </div>

            <!-- å¯¹è¯ç»“æœ -->
            <div class="setting-item" v-if="llmChatResult">
              <label>AIå›å¤:</label>
              <div class="chat-result">
                <div class="chat-message user-message">
                  <strong>ç”¨æˆ·:</strong> {{ llmLastUserMessage }}
                </div>
                <div class="chat-message ai-message">
                  <strong>AI:</strong> {{ llmChatResult }}
                </div>
                <div v-if="llmChatDuration" class="chat-info">
                  è€—æ—¶: {{ llmChatDuration }}ç§’ | æ¨¡å‹: {{ selectedLlmModel }}
                </div>
              </div>
            </div>
          </div>

        </div>
        <!-- LLMè®¾ç½®å­åŒºåŸŸç»“æŸ -->
        
        <div v-if="!aiConfigured" class="not-configured-message">
          <p>âš ï¸ è¯·å…ˆé…ç½®API Tokenæ‰èƒ½ä½¿ç”¨AIåŠŸèƒ½ï¼ˆSTTå’ŒLLMï¼‰ã€‚</p>
          <p>æ‚¨å¯ä»¥åœ¨ç¡…åŸºæµåŠ¨å®˜ç½‘è·å–API Tokenã€‚</p>
        </div>
      </div>

      <!-- å…¶ä»–è®¾ç½®åŒºåŸŸå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ  -->
      <div class="settings-section">
        <h2>ğŸ”§ å…¶ä»–è®¾ç½®</h2>
        <div class="setting-item">
          <p class="placeholder-text">æ›´å¤šè®¾ç½®é€‰é¡¹å³å°†æ¨å‡º...</p>
        </div>
      </div>
    </div>

  </div>
</template>

<script setup>
import { ref, onMounted, onUnmounted } from 'vue'
import { useAiStore } from '@/stores/aiStore'

// åˆå§‹åŒ–Pinia store
const aiStore = useAiStore()

// å“åº”å¼æ•°æ®
const ttsSupported = ref(false)
const availableVoices = ref([])
const selectedVoice = ref('')
const voiceRate = ref(0)
const testText = ref('ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªTTSæµ‹è¯•ã€‚Hello, this is a TTS test.')
const loading = ref(false)
const isSpeaking = ref(false)
const statusMessage = ref('')
const statusType = ref('info') // 'info', 'success', 'error'

// AIé…ç½®ç°åœ¨é€šè¿‡aiStoreç®¡ç†ï¼Œåˆ›å»ºè®¡ç®—å±æ€§æ¥è®¿é—®
const aiToken = ref('')
const aiConfigured = ref(false)
const aiStatusMessage = ref('')
const aiStatusType = ref('info')

// STTç›¸å…³å“åº”å¼æ•°æ®
const isRecording = ref(false)
const isTranscribing = ref(false)
const transcriptionResult = ref('')
const mediaRecorder = ref(null)
const audioChunks = ref([])
const recordedAudioBlob = ref(null)
const hasRecording = ref(false)
const isPlaying = ref(false)
const audioPlayer = ref(null)

// LLMç›¸å…³å“åº”å¼æ•°æ®
const selectedLlmModel = ref('Qwen/Qwen2.5-7B-Instruct')
const availableLlmModels = ref([])
const llmTestMessage = ref('ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚')
const isLlmChatting = ref(false)
const llmChatResult = ref('')
const llmLastUserMessage = ref('')
const llmChatDuration = ref(null)

// æ˜¾ç¤ºçŠ¶æ€æ¶ˆæ¯
const showStatus = (message, type = 'info', duration = 3000) => {
  statusMessage.value = message
  statusType.value = type
  setTimeout(() => {
    statusMessage.value = ''
  }, duration)
}

// æ˜¾ç¤ºAIçŠ¶æ€æ¶ˆæ¯
const showAiStatus = (message, type = 'info', duration = 3000) => {
  aiStatusMessage.value = message
  aiStatusType.value = type
  setTimeout(() => {
    aiStatusMessage.value = ''
  }, duration)
}

// æ£€æŸ¥TTSæ”¯æŒ
const checkTTSSupport = async () => {
  try {
    loading.value = true
    const result = await window.electronAPI.invoke('tts-check-support')
    if (result.success) {
        ttsSupported.value = result.data
        if (ttsSupported.value) {
          await loadAvailableVoices()
        }
      } else {
      showStatus('æ£€æŸ¥TTSæ”¯æŒå¤±è´¥: ' + result.error, 'error')
    }
  } catch (error) {
    console.error('æ£€æŸ¥TTSæ”¯æŒå¤±è´¥:', error)
    showStatus('æ£€æŸ¥TTSæ”¯æŒå¤±è´¥', 'error')
  } finally {
    loading.value = false
  }
}

// åŠ è½½å¯ç”¨è¯­éŸ³åˆ—è¡¨
const loadAvailableVoices = async () => {
  try {
    const result = await window.electronAPI.invoke('tts-get-voices')
    if (result.success) {
      availableVoices.value = result.data
      if (availableVoices.value.length > 0) {
        selectedVoice.value = availableVoices.value[0].Name
      }
    } else {
      showStatus('è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥: ' + result.error, 'error')
    }
  } catch (error) {
    console.error('è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥:', error)
    showStatus('è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥', 'error')
  }
}

// è¯­éŸ³å˜æ›´å¤„ç†
const onVoiceChange = () => {
  showStatus('è¯­éŸ³å·²æ›´æ”¹', 'success')
}

// è¯­éŸ³é€Ÿåº¦å˜æ›´å¤„ç†
const onVoiceRateChange = () => {
  // å®æ—¶æ›´æ–°ï¼Œä¸æ˜¾ç¤ºæ¶ˆæ¯
}

// æµ‹è¯•TTS
const testTTS = async () => {
  if (!testText.value.trim()) {
    showStatus('è¯·è¾“å…¥æµ‹è¯•æ–‡æœ¬', 'error')
    return
  }

  try {
    isSpeaking.value = true
    const options = {
      voice: selectedVoice.value,
      rate: parseInt(voiceRate.value)
    }
    
    const result = await window.electronAPI.invoke('tts-speak', testText.value, options)
    if (result.success) {
      showStatus('TTSæ’­æ”¾å®Œæˆ', 'success')
    } else {
      showStatus('TTSæ’­æ”¾å¤±è´¥: ' + result.error, 'error')
    }
  } catch (error) {
    console.error('TTSæ’­æ”¾å¤±è´¥:', error)
    showStatus('TTSæ’­æ”¾å¤±è´¥', 'error')
  } finally {
    isSpeaking.value = false
  }
}

// åœæ­¢TTS
const stopTTS = async () => {
  try {
    const result = await window.electronAPI.invoke('tts-stop')
    if (result.success) {
      showStatus('TTSæ’­æ”¾å·²åœæ­¢', 'success')
    } else {
      showStatus('åœæ­¢TTSå¤±è´¥: ' + result.error, 'error')
    }
  } catch (error) {
    console.error('åœæ­¢TTSå¤±è´¥:', error)
    showStatus('åœæ­¢TTSå¤±è´¥', 'error')
  } finally {
    isSpeaking.value = false
  }
}

// AIç»Ÿä¸€é…ç½®æ–¹æ³•
const loadAiConfig = async () => {
  try {
    await aiStore.loadConfig()
    // åŒæ­¥storeçŠ¶æ€åˆ°æœ¬åœ°å“åº”å¼å˜é‡
    aiToken.value = aiStore.apiToken
    aiConfigured.value = aiStore.isConfigured
  } catch (error) {
    console.error('åŠ è½½AIé…ç½®å¤±è´¥:', error)
  }
}

const saveAiToken = async () => {
  if (!aiToken.value.trim()) {
    showAiStatus('è¯·è¾“å…¥æœ‰æ•ˆçš„API Token', 'error')
    return
  }

  try {
    loading.value = true
    aiStore.setApiToken(aiToken.value.trim())
    aiConfigured.value = aiStore.isConfigured
    showAiStatus('API Tokenä¿å­˜æˆåŠŸ', 'success')
    // é‡æ–°åŠ è½½LLMæ¨¡å‹åˆ—è¡¨
    await loadLlmModels()
  } catch (error) {
    console.error('ä¿å­˜AI Tokenå¤±è´¥:', error)
    showAiStatus('ä¿å­˜å¤±è´¥', 'error')
  } finally {
    loading.value = false
  }
}

const testAiConnection = async () => {
  try {
    loading.value = true
    console.log('[Settings] å¼€å§‹æµ‹è¯•AIè¿æ¥')
    const result = await aiStore.testConnection()
    console.log('[Settings] AIè¿æ¥æµ‹è¯•ç»“æœ:', result)
    
    if (result.success) {
      showAiStatus('è¿æ¥æµ‹è¯•æˆåŠŸ', 'success')
    } else {
      const errorMsg = result.error || 'è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥API Tokenæ˜¯å¦æ­£ç¡®'
      console.error('[Settings] AIè¿æ¥æµ‹è¯•å¤±è´¥:', errorMsg)
      showAiStatus(`è¿æ¥æµ‹è¯•å¤±è´¥: ${errorMsg}`, 'error')
    }
  } catch (error) {
    console.error('[Settings] AIè¿æ¥æµ‹è¯•å¼‚å¸¸:', error)
    console.error('[Settings] é”™è¯¯å †æ ˆ:', error.stack)
    showAiStatus(`è¿æ¥æµ‹è¯•å¼‚å¸¸: ${error.message}`, 'error')
  } finally {
    loading.value = false
  }
}

const startRecording = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    mediaRecorder.value = new MediaRecorder(stream)
    audioChunks.value = []
    
    mediaRecorder.value.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.value.push(event.data)
      }
    }
    
    mediaRecorder.value.onstop = async () => {
      const audioBlob = new Blob(audioChunks.value, { type: 'audio/wav' })
      recordedAudioBlob.value = audioBlob
      hasRecording.value = true
      await transcribeAudio(audioBlob)
      
      // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
      stream.getTracks().forEach(track => track.stop())
    }
    
    mediaRecorder.value.start()
    isRecording.value = true
    transcriptionResult.value = ''
    showStatus('å¼€å§‹å½•éŸ³...', 'info')
  } catch (error) {
    console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error)
    showStatus('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®', 'error')
  }
}

const stopRecording = () => {
  if (mediaRecorder.value && isRecording.value) {
    mediaRecorder.value.stop()
    isRecording.value = false
    showStatus('å½•éŸ³ç»“æŸï¼Œæ­£åœ¨è½¬å½•...', 'info')
  }
}

const transcribeAudio = async (audioBlob) => {
  try {
    isTranscribing.value = true
    
    // å°†Blobè½¬æ¢ä¸ºArrayBuffer
    const arrayBuffer = await audioBlob.arrayBuffer()
    const uint8Array = new Uint8Array(arrayBuffer)
    
    const result = await window.electronAPI.invoke('stt-transcribe', uint8Array)
    if (result.success) {
      transcriptionResult.value = result.data
      showStatus('è½¬å½•å®Œæˆ', 'success')
    } else {
      showStatus('è½¬å½•å¤±è´¥: ' + result.error, 'error')
    }
  } catch (error) {
    console.error('è½¬å½•å¤±è´¥:', error)
    showStatus('è½¬å½•å¤±è´¥', 'error')
  } finally {
    isTranscribing.value = false
  }
}

const playRecording = () => {
  if (!recordedAudioBlob.value) {
    showStatus('æ²¡æœ‰å¯æ’­æ”¾çš„å½•éŸ³', 'warning')
    return
  }
  
  try {
    // åˆ›å»ºéŸ³é¢‘URL
    const audioUrl = URL.createObjectURL(recordedAudioBlob.value)
    
    // åˆ›å»ºéŸ³é¢‘æ’­æ”¾å™¨
    audioPlayer.value = new Audio(audioUrl)
    
    // è®¾ç½®æ’­æ”¾ç»“æŸäº‹ä»¶
    audioPlayer.value.onended = () => {
      isPlaying.value = false
      URL.revokeObjectURL(audioUrl)
      audioPlayer.value = null
      showStatus('å½•éŸ³æ’­æ”¾å®Œæˆ', 'success')
    }
    
    // è®¾ç½®æ’­æ”¾é”™è¯¯äº‹ä»¶
    audioPlayer.value.onerror = (error) => {
      console.error('æ’­æ”¾å½•éŸ³å¤±è´¥:', error)
      isPlaying.value = false
      URL.revokeObjectURL(audioUrl)
      audioPlayer.value = null
      showStatus('æ’­æ”¾å½•éŸ³å¤±è´¥', 'error')
    }
    
    // å¼€å§‹æ’­æ”¾
    audioPlayer.value.play()
    isPlaying.value = true
    showStatus('å¼€å§‹æ’­æ”¾å½•éŸ³...', 'info')
  } catch (error) {
    console.error('æ’­æ”¾å½•éŸ³å¤±è´¥:', error)
    showStatus('æ’­æ”¾å½•éŸ³å¤±è´¥', 'error')
  }
}

const stopPlayback = () => {
  if (audioPlayer.value) {
    audioPlayer.value.pause()
    audioPlayer.value.currentTime = 0
    
    // æ¸…ç†èµ„æº
    const audioUrl = audioPlayer.value.src
    if (audioUrl.startsWith('blob:')) {
      URL.revokeObjectURL(audioUrl)
    }
    
    audioPlayer.value = null
    isPlaying.value = false
    showStatus('åœæ­¢æ’­æ”¾å½•éŸ³', 'info')
  }
}



// LLMç›¸å…³æ–¹æ³•
const loadLlmModels = async () => {
  try {
    const modelsResult = await window.electronAPI.invoke('ai-get-models')
    if (modelsResult.success) {
      availableLlmModels.value = modelsResult.data
    }
  } catch (error) {
    console.error('åŠ è½½LLMæ¨¡å‹å¤±è´¥:', error)
  }
}

const testLlmChat = async () => {
  if (!llmTestMessage.value.trim()) {
    showAiStatus('è¯·è¾“å…¥æµ‹è¯•æ¶ˆæ¯', 'warning')
    return
  }
  
  try {
    isLlmChatting.value = true
    llmLastUserMessage.value = llmTestMessage.value
    showAiStatus('æ­£åœ¨å¯¹è¯...', 'info')
    
    console.log('[Settings] å¼€å§‹LLMå¯¹è¯æµ‹è¯•')
    console.log('[Settings] æµ‹è¯•æ¶ˆæ¯:', llmTestMessage.value)
    console.log('[Settings] é€‰ä¸­çš„æ¨¡å‹:', selectedLlmModel.value)
    
    const options = {
      model: selectedLlmModel.value,
      maxTokens: 1000
    }
    
    console.log('[Settings] å¯¹è¯é€‰é¡¹:', options)
    const result = await aiStore.sendChatMessage(llmTestMessage.value, options)
    console.log('[Settings] LLMå¯¹è¯ç»“æœ:', result)
    
    if (result && result.success) {
      llmChatResult.value = result.data.content
      llmChatDuration.value = result.data.duration?.toFixed(2)
      showAiStatus('å¯¹è¯å®Œæˆ', 'success')
      console.log('[Settings] LLMå¯¹è¯æˆåŠŸï¼Œå†…å®¹é•¿åº¦:', result.data.content?.length)
    } else {
      const errorMsg = result?.error || 'æœªçŸ¥é”™è¯¯'
      console.error('[Settings] LLMå¯¹è¯å¤±è´¥:', errorMsg)
      console.error('[Settings] å®Œæ•´é”™è¯¯ä¿¡æ¯:', result)
      showAiStatus('å¯¹è¯å¤±è´¥: ' + errorMsg, 'error')
    }
  } catch (error) {
    console.error('[Settings] LLMå¯¹è¯å¼‚å¸¸:', error)
    console.error('[Settings] é”™è¯¯å †æ ˆ:', error.stack)
    showAiStatus('å¯¹è¯å¼‚å¸¸: ' + error.message, 'error')
  } finally {
    isLlmChatting.value = false
  }
}

const clearLlmChat = () => {
  llmChatResult.value = ''
  llmLastUserMessage.value = ''
  llmChatDuration.value = null
  llmTestMessage.value = 'ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚'
  showAiStatus('å¯¹è¯å·²æ¸…ç©º', 'info')
}

// ç»„ä»¶æŒ‚è½½æ—¶åˆå§‹åŒ–
onMounted(() => {
  checkTTSSupport()
  loadAiConfig()
  loadLlmModels()
})

// ç»„ä»¶å¸è½½æ—¶æ¸…ç†
onUnmounted(() => {
  if (isSpeaking.value) {
    stopTTS()
  }
  
  // æ¸…ç†éŸ³é¢‘æ’­æ”¾å™¨
  if (audioPlayer.value) {
    stopPlayback()
  }
  
  // æ¸…ç†å½•éŸ³èµ„æº
  if (recordedAudioBlob.value) {
    recordedAudioBlob.value = null
    hasRecording.value = false
  }
})
</script>

<style scoped>
.settings {
  padding: 20px;
  max-width: 800px;
  margin: 0 auto;
}

.settings-header {
  margin-bottom: 30px;
  text-align: center;
}

.settings-header h1 {
  color: #2c3e50;
  margin-bottom: 10px;
}

.settings-header p {
  color: #7f8c8d;
  font-size: 16px;
}

.settings-content {
  display: flex;
  flex-direction: column;
  gap: 30px;
}

.settings-section {
  background: #f8f9fa;
  border-radius: 8px;
  padding: 20px;
  border: 1px solid #e9ecef;
}

.settings-section h2 {
  color: #2c3e50;
  margin-bottom: 20px;
  font-size: 18px;
  border-bottom: 2px solid #3498db;
  padding-bottom: 10px;
}

.setting-item {
  margin-bottom: 20px;
}

.setting-item label {
  display: block;
  margin-bottom: 8px;
  font-weight: 600;
  color: #34495e;
}

.setting-item select,
.setting-item textarea {
  width: 100%;
  padding: 10px;
  border: 1px solid #ddd;
  border-radius: 4px;
  font-size: 14px;
  transition: border-color 0.3s ease;
}

.setting-item select:focus,
.setting-item textarea:focus {
  outline: none;
  border-color: #3498db;
  box-shadow: 0 0 0 2px rgba(52, 152, 219, 0.2);
}

.setting-item select:disabled,
.setting-item textarea:disabled {
  background-color: #f5f5f5;
  cursor: not-allowed;
}

.slider-container {
  display: flex;
  align-items: center;
  gap: 15px;
}

.slider-container input[type="range"] {
  flex: 1;
  height: 6px;
  background: #ddd;
  border-radius: 3px;
  outline: none;
}

.slider-container input[type="range"]::-webkit-slider-thumb {
  appearance: none;
  width: 20px;
  height: 20px;
  background: #3498db;
  border-radius: 50%;
  cursor: pointer;
}

.slider-container input[type="range"]::-moz-range-thumb {
  width: 20px;
  height: 20px;
  background: #3498db;
  border-radius: 50%;
  cursor: pointer;
  border: none;
}

.slider-value {
  min-width: 50px;
  text-align: center;
  font-weight: 600;
  color: #2c3e50;
}

.button-group {
  display: flex;
  gap: 10px;
}

.btn {
  padding: 10px 20px;
  border: none;
  border-radius: 4px;
  font-size: 14px;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.3s ease;
  display: flex;
  align-items: center;
  gap: 5px;
}

.btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

.btn-primary {
  background-color: #3498db;
  color: white;
}

.btn-primary:hover:not(:disabled) {
  background-color: #2980b9;
}

.btn-secondary {
  background-color: #95a5a6;
  color: white;
}

.btn-secondary:hover:not(:disabled) {
  background-color: #7f8c8d;
}

.status {
  font-weight: 600;
  padding: 5px 10px;
  border-radius: 4px;
}

.status.supported {
  background-color: #d4edda;
  color: #155724;
}

.status.not-supported {
  background-color: #f8d7da;
  color: #721c24;
}

.not-supported-message,
.not-configured-message {
  background: #fff3cd;
  border: 1px solid #ffeaa7;
  border-radius: 4px;
  padding: 15px;
  margin-top: 15px;
}

.not-supported-message p,
.not-configured-message p {
  margin: 5px 0;
  color: #856404;
}

/* STTç›¸å…³æ ·å¼ */
.token-input-group {
  display: flex;
  gap: 10px;
  align-items: center;
}

.token-input-group input {
  flex: 1;
}

.recording-controls {
  display: flex;
  gap: 10px;
  flex-wrap: wrap;
}

.transcription-result {
  background: #f8f9fa;
  border: 1px solid #e9ecef;
  border-radius: 4px;
  padding: 15px;
  margin-top: 10px;
  font-family: monospace;
  white-space: pre-wrap;
  word-break: break-word;
}

.transcribing-status {
  background: #e3f2fd;
  border: 1px solid #bbdefb;
  border-radius: 4px;
  padding: 10px;
  color: #1976d2;
  text-align: center;
  font-weight: 500;
}

.status.configured {
  color: #27ae60;
  font-weight: 600;
}

.status.not-configured {
  color: #e74c3c;
  font-weight: 600;
}

.btn-info {
  background: #17a2b8;
  color: white;
  border: 1px solid #17a2b8;
}

.btn-info:hover {
  background: #138496;
  border-color: #117a8b;
}

.btn-info:disabled {
  background: #6c757d;
  border-color: #6c757d;
  opacity: 0.6;
  cursor: not-allowed;
}

.btn-warning {
  background: #ffc107;
  color: #212529;
  border: 1px solid #ffc107;
}

.btn-warning:hover:not(:disabled) {
  background: #e0a800;
  border-color: #d39e00;
}

.btn-warning:disabled {
  background: #6c757d;
  border-color: #6c757d;
  opacity: 0.6;
  cursor: not-allowed;
}

.placeholder-text {
  color: #7f8c8d;
  font-style: italic;
  text-align: center;
  padding: 20px;
}

.status-message {
  margin-top: 10px;
  padding: 8px 12px;
  border-radius: 4px;
  font-weight: 500;
  font-size: 14px;
  animation: fadeIn 0.3s ease;
}

.status-message.info {
  background-color: #d1ecf1;
  color: #0c5460;
  border: 1px solid #bee5eb;
}

.status-message.success {
  background-color: #d4edda;
  color: #155724;
  border: 1px solid #c3e6cb;
}

.status-message.error {
  background-color: #f8d7da;
  color: #721c24;
  border: 1px solid #f5c6cb;
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(-10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

/* AIåŠŸèƒ½è®¾ç½®ç›¸å…³æ ·å¼ */
.ai-subsection {
  margin-bottom: 25px;
  padding: 15px;
  background: #ffffff;
  border-radius: 6px;
  border: 1px solid #e0e0e0;
}

.ai-subsection h3 {
  color: #2c3e50;
  margin-bottom: 15px;
  font-size: 16px;
  border-bottom: 1px solid #ecf0f1;
  padding-bottom: 8px;
}

/* LLMå¯¹è¯ç»“æœæ ·å¼ */
.chat-result {
  background: #f8f9fa;
  border: 1px solid #e9ecef;
  border-radius: 6px;
  padding: 15px;
  margin-top: 10px;
}

.chat-message {
  margin-bottom: 10px;
  padding: 8px 12px;
  border-radius: 4px;
  word-wrap: break-word;
}

.user-message {
  background: #e3f2fd;
  border-left: 3px solid #2196f3;
}

.ai-message {
  background: #f3e5f5;
  border-left: 3px solid #9c27b0;
}

.chat-info {
  font-size: 12px;
  color: #666;
  text-align: right;
  margin-top: 8px;
  padding-top: 8px;
  border-top: 1px solid #e0e0e0;
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 768px) {
  .settings {
    padding: 15px;
  }
  
  .button-group {
    flex-direction: column;
  }
  
  .slider-container {
    flex-direction: column;
    align-items: stretch;
  }
  
  .status-message {
    position: relative;
    top: auto;
    right: auto;
    margin-top: 20px;
  }
}
</style>